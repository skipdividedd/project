{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307083c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699c4f4",
   "metadata": {},
   "source": [
    "#### О данных, на которых делали пробинг грамматических категорий в BERT:\n",
    "\n",
    "1. en_ewt -- Genre: blog, social, reviews, email, web\n",
    "\n",
    "2. en_gum -- Genre: academic, blog, fiction, government, news, nonfiction, social, spoken, web, wiki\n",
    "\n",
    "#### Какие категории были:\n",
    "\n",
    "* Общие для двух датасетов\n",
    "\n",
    "1. Case\n",
    "* Nom (The point was; He said; I said)\n",
    "* Gen (Despite Daniel' s attempts; Blood smeared the back of his hand)\n",
    "* Acc (Wash the leaves; Got it)\n",
    "\n",
    "    То есть тут существительные и местоимения.\n",
    "\n",
    "2. Gender\n",
    "* Masc (Dvořák ' s first piece; He / his)\n",
    "* Fem (Kiara Perkins; She joined)\n",
    "* Neut (In other words; It is unsurprising)\n",
    "\n",
    "    Тут существительные собственные и нарицательные, местоимения.\n",
    "\n",
    "3. Definite\n",
    "* Ind (When regarding an artwork; a)\n",
    "* Def (I shall leave this office; the)\n",
    "\n",
    "    Тут артикли и указательные местоимения.\n",
    "\n",
    "4. Number\n",
    "* Sing (As a foreign visitor; Gonna rip your purse; Seen this before; I know it)\n",
    "* Plur (Six months; See what else we got here; Let' s just double check that)\n",
    "\n",
    "    Тут существительные, местоимения, глаголы в каких то случаях кажется. \n",
    "\n",
    "5. Person\n",
    "* 1 (I / We)\n",
    "* 2 (You / Your; Just be aware)\n",
    "* 3 (всякое разное)\n",
    "\n",
    "    Тут местоимения, глагол.\n",
    "\n",
    "6. Degree\n",
    "* Pos (Although useful; Some disciplines; In computer science)\n",
    "* Cmp (much smaller; more details; sooner or later; explain more)\n",
    "* Sup (On the hottest days; Most of the rooms)\n",
    "\n",
    "    Тут прилагательные, неопределенное местоимение, наречия (?). \n",
    "\n",
    "7. NumForm\n",
    "\n",
    "* Digit (13; + всякая каша; Ø -- символы)\n",
    "* Word (one; five; + каша)\n",
    "* Roman (I, II)\n",
    "\n",
    "    Числительные.\n",
    "\n",
    "8. NumType\n",
    "* Ord (first; 17th; + каша)\n",
    "* Card (1; 2014; one)\n",
    "* Mult (once; twice) -- мало их\n",
    "* Frac (2.4) -- мало их\n",
    "\n",
    "    Числительные.\n",
    "\n",
    "9. Mood\n",
    "* Ind\n",
    "* Imp (Press okay)\n",
    "* Sub (только в EWT и очень мало)\n",
    "\n",
    "    Наклонение.\n",
    "\n",
    "10. Tense\n",
    "* Past\n",
    "* Pres\n",
    "\n",
    "    Кажется тут только время глагола.\n",
    "\n",
    "11. VerbForm\n",
    "* Fin \n",
    "* Part \n",
    "* Inf \n",
    "* Ger \n",
    "\n",
    "\n",
    "\n",
    "* Различающиеся категории датасетов\n",
    "\n",
    "12. PronType (GUM)\n",
    "* Neg \n",
    "* Dem \n",
    "* Tot \n",
    "* Rel \n",
    "* Int \n",
    "* Prs \n",
    "* Emp \n",
    "* Ind \n",
    "* Art \n",
    "\n",
    "    Для EWT и GUM было предупреждение The classes in train and validation parts are different for category \"PronType\", но с EWT и в итоге падала ошибка на пробинге.\n",
    "    \n",
    "12. ExtPos (EWT)\n",
    "* ADV \n",
    "* CCONJ \n",
    "* PRON \n",
    "* SCONJ \n",
    "* ADP (figures such as the Pope (such = ADJ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b1e30",
   "metadata": {},
   "source": [
    "#### Как делали: \n",
    "\n",
    "При помощи NeuroX tooklit\n",
    "\n",
    "1. Даем conllu файлы AIRI Probing_framework\n",
    "2. Конвертируем .csv файлы в .txt формат и делаем разные файлы для train и test. \n",
    "* ограничиваю длину предложения: 5 < len(sentence.split()) < 40\n",
    "* беру максимум 2600 предложений для train и 900 для test (эмбеддинги очень много весят) в каждой категории.\n",
    "* делаю balanced-sampling, чтобы отбирать одинаковое количество предложений для каждого лейбла в грамматической категории\n",
    "\n",
    "! Ошибка -- минимальный порог слишком высок. Надо ставить длину 2-3, а не 5.\n",
    "\n",
    "! Проблема -- недостаточное количество данных для некоторых меток. Возможно, отчасти из-за ограничений на длину предложения, но также потому что их просто недостаточно. \n",
    "Гипотетическое решение: подумать, как вытаскивать эти данные из неиспользуемых train-данных.\n",
    "* NeuroX дает эмбеддинги для каждого предложения в train и test.\n",
    "3. Подаю данные в NeuroX: \n",
    "* linear_probe.train_logistic_regression_probe -- тренируем\n",
    "* linear_probe.evaluate_probe -- получаю accuracy для train и test. \n",
    "Гипотетически можно поставить F1, среднее accuracy и F1, pearson.\n",
    "* получаю ранжирование по нейронам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec3552",
   "metadata": {},
   "source": [
    "### Загружаем метрики и ранжирование нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f496ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scores_ewt.pkl', 'rb') as f:\n",
    "    scores_ewt = pickle.load(f)\n",
    "with open('neurons_ewt.pkl', 'rb') as f:\n",
    "    ordered_neurons_ewt = pickle.load(f)\n",
    "with open('scores_gum.pkl', 'rb') as f:\n",
    "    scores_gum = pickle.load(f)\n",
    "with open('neurons_gum.pkl', 'rb') as f:\n",
    "    ordered_neurons_gum = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf22fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_scores(scores):\n",
    "    for k, v in scores.items():\n",
    "        m1 = []\n",
    "        m2 = []\n",
    "\n",
    "        for i, j in v[0].items():\n",
    "\n",
    "            if v[0][i] < 0.5:\n",
    "\n",
    "                if not m1.__contains__(v[0]):\n",
    "                    m1.append(v[0])\n",
    "\n",
    "                print(k, i, 'train_score', v[0][i])\n",
    "        if m1:\n",
    "            print(k, 'train', m1)\n",
    "            print('---------------------')\n",
    "\n",
    "        for i, j in v[1].items():\n",
    "            if v[1][i] < 0.5:\n",
    "\n",
    "                if not m2.__contains__(v[1]):\n",
    "                    m2.append(v[1])\n",
    "\n",
    "                print(k, i, 'test_score', v[1][i])\n",
    "        if m2:\n",
    "            print(k, 'test', m2)\n",
    "            print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3909c3",
   "metadata": {},
   "source": [
    "### Плохая классификация для датасета en_ewt (accuracy < 0.5)\n",
    "\n",
    "Genre: blog, social, reviews, email, web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0bc411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VerbForm __OVERALL__ test_score 0.2490372272143774\n",
      "VerbForm Fin test_score 0.49333333333333335\n",
      "VerbForm Part test_score 0.1288888888888889\n",
      "VerbForm Inf test_score 0.008888888888888889\n",
      "VerbForm test [{'__OVERALL__': 0.2490372272143774, 'Fin': 0.49333333333333335, 'Ger': 0.5, 'Part': 0.1288888888888889, 'Inf': 0.008888888888888889}]\n",
      "---------------------\n",
      "NumForm Roman test_score 0.0\n",
      "NumForm test [{'__OVERALL__': 0.7839080459770115, 'Word': 0.7251908396946565, 'Roman': 0.0, 'Digit': 0.82}]\n",
      "---------------------\n",
      "ExtPos CCONJ test_score 0.25\n",
      "ExtPos PRON test_score 0.0\n",
      "ExtPos SCONJ test_score 0.0\n",
      "ExtPos ADP test_score 0.36363636363636365\n",
      "ExtPos test [{'__OVERALL__': 0.5945945945945946, 'ADV': 0.85, 'CCONJ': 0.25, 'PRON': 0.0, 'SCONJ': 0.0, 'ADP': 0.36363636363636365}]\n",
      "---------------------\n",
      "Mood Sub train_score 0.2\n",
      "Mood train [{'__OVERALL__': 0.9910884786760026, 'Ind': 0.9965397923875432, 'Sub': 0.2, 'Imp': 0.9899856938483548}]\n",
      "---------------------\n",
      "Mood Sub test_score 0.0\n",
      "Mood test [{'__OVERALL__': 0.9501039501039501, 'Ind': 0.9533333333333334, 'Sub': 0.0, 'Imp': 0.9553072625698324}]\n",
      "---------------------\n",
      "Gender Masc test_score 0.05303030303030303\n",
      "Gender Fem test_score 0.26\n",
      "Gender test [{'__OVERALL__': 0.6182572614107884, 'Masc': 0.05303030303030303, 'Fem': 0.26, 'Neut': 0.9266666666666666}]\n",
      "---------------------\n",
      "NumType Mult test_score 0.1111111111111111\n",
      "NumType Frac test_score 0.0\n",
      "NumType test [{'__OVERALL__': 0.7615658362989324, 'Mult': 0.1111111111111111, 'Ord': 0.6046511627906976, 'Card': 0.8311111111111111, 'Frac': 0.0}]\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "bad_scores(scores_ewt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a3e75",
   "metadata": {},
   "source": [
    "### Вывод после пробинга на en_ewt:\n",
    "\n",
    "Для некоторых лейблов в грамматических категориях ОЧЕНЬ плохая метрика test_score. Потому что там было очень мало данных. \n",
    "\n",
    "Крайний пример:\n",
    "\n",
    "Mood Sub -- плохая метрика и в train (0.2), и в test (0.0) -- 5 предложений в train и 2 в test. \n",
    "\n",
    "OVERALL плохая метрика -- для VerbForm (test_score 0.249). \n",
    "Хотя там было сравнительно нормальное количество данных -- 2188 в train и 779 в test. Но в категории 4 лейбла -- значит надо больше данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7eb1fe",
   "metadata": {},
   "source": [
    "### Плохая классификация для датасета en_gum\n",
    "\n",
    "Genre: academic, blog, fiction, government, news, nonfiction, social, spoken, web, wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e318ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VerbForm Fin test_score 0.4088888888888889\n",
      "VerbForm test [{'__OVERALL__': 0.6628571428571428, 'Inf': 0.874439461883408, 'Part': 0.7155555555555555, 'Ger': 0.5925925925925926, 'Fin': 0.4088888888888889}]\n",
      "---------------------\n",
      "NumForm Roman test_score 0.0\n",
      "NumForm test [{'__OVERALL__': 0.6887052341597796, 'Word': 0.7959183673469388, 'Digit': 0.6273584905660378, 'Roman': 0.0}]\n",
      "---------------------\n",
      "PronType Neg test_score 0.0\n",
      "PronType Rel test_score 0.14285714285714285\n",
      "PronType Rcp test_score 0.0\n",
      "PronType test [{'__OVERALL__': 0.682648401826484, 'Neg': 0.0, 'Dem': 0.7777777777777778, 'Tot': 0.5833333333333334, 'Rel': 0.14285714285714285, 'Int': 0.8688524590163934, 'Prs': 0.7333333333333333, 'Rcp': 0.0, 'Ind': 0.5714285714285714, 'Art': 0.7222222222222222}]\n",
      "---------------------\n",
      "Gender Fem test_score 0.015873015873015872\n",
      "Gender Masc test_score 0.1592356687898089\n",
      "Gender test [{'__OVERALL__': 0.5123595505617977, 'Fem': 0.015873015873015872, 'Masc': 0.1592356687898089, 'Neut': 0.8977777777777778}]\n",
      "---------------------\n",
      "Case Acc test_score 0.2727272727272727\n",
      "Case test [{'__OVERALL__': 0.7177700348432056, 'Gen': 0.9035532994923858, 'Acc': 0.2727272727272727, 'Nom': 0.71}]\n",
      "---------------------\n",
      "NumType Ord train_score 0.32057416267942584\n",
      "NumType train [{'__OVERALL__': 0.8204570184983678, 'Ord': 0.32057416267942584, 'Frac': 0.6666666666666666, 'Card': 0.9923076923076923, 'Mult': 0.7619047619047619}]\n",
      "---------------------\n",
      "NumType Ord test_score 0.10144927536231885\n",
      "NumType Frac test_score 0.0625\n",
      "NumType Mult test_score 0.14285714285714285\n",
      "NumType test [{'__OVERALL__': 0.7192429022082019, 'Ord': 0.10144927536231885, 'Frac': 0.0625, 'Card': 0.9733333333333334, 'Mult': 0.14285714285714285}]\n",
      "---------------------\n",
      "Degree Cmp test_score 0.26666666666666666\n",
      "Degree Sup test_score 0.2972972972972973\n",
      "Degree test [{'__OVERALL__': 0.7696335078534031, 'Cmp': 0.26666666666666666, 'Pos': 0.9033333333333333, 'Sup': 0.2972972972972973}]\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "bad_scores(scores_gum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223cc40c",
   "metadata": {},
   "source": [
    "### Вывод после пробинга на en_gum:\n",
    "\n",
    "\n",
    "Нет Overall плохих метрик для целой категории.\n",
    "\n",
    "Есть плохие метрики для лейблов в категориях.\n",
    "\n",
    "Как и в en_ewt: плохие метрики для лейблов в Gender (Fem, Masc), NumType (Mult, Frac), NumForm (Roman??).\n",
    "\n",
    "Внезапное, что не было плохо на en_ewt: Degree (Cmp, Sup), Case (Acc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f14e9",
   "metadata": {},
   "source": [
    "### Просто посмотреть на N нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861308f",
   "metadata": {},
   "source": [
    "В чем суть:\n",
    "пока простой тупой метод посмотреть общий set(нейронов), если для каждой категории выбираем N-top нейронов в ранжировании. \n",
    "\n",
    "Всего нейронов в BERT 9984 (13 слоев * 768 -- размерность эмбеддинга).\n",
    "\n",
    "Всего в каждом датасете было 12 категорий. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a257077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_common_neurons(n, dct):\n",
    "    number_cats, neurons_list = 0, []\n",
    "    for k, v in dct.items():\n",
    "        v = v[:n]\n",
    "        neurons_list+=v\n",
    "        number_cats+=1\n",
    "    f1 = f'All neuron number if {n} for each category -- {len(neurons_list)} among {number_cats} categories'\n",
    "    f2 = f'Unique neuron number if {n} for each category -- {len(set(neurons_list))} among {number_cats} categories'\n",
    "    return f1, f2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dda310",
   "metadata": {},
   "source": [
    "#### 10 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87a13c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 10 for each category -- 120 among 12 categories',\n",
       " 'Unique neuron number if 10 for each category -- 114 among 12 categories')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(10, ordered_neurons_ewt) #EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3535e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 10 for each category -- 120 among 12 categories',\n",
       " 'Unique neuron number if 10 for each category -- 118 among 12 categories')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(10, ordered_neurons_gum) #GUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9ab1a",
   "metadata": {},
   "source": [
    "#### 100 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132e24ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 100 for each category -- 1200 among 12 categories',\n",
       " 'Unique neuron number if 100 for each category -- 1073 among 12 categories')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(100, ordered_neurons_ewt) #EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c96d14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 100 for each category -- 1200 among 12 categories',\n",
       " 'Unique neuron number if 100 for each category -- 1088 among 12 categories')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(100, ordered_neurons_gum) #GUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f22a9",
   "metadata": {},
   "source": [
    "#### 300 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96101b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 300 for each category -- 3600 among 12 categories',\n",
       " 'Unique neuron number if 300 for each category -- 2799 among 12 categories')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(300, ordered_neurons_ewt) #EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41edef99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 300 for each category -- 3600 among 12 categories',\n",
       " 'Unique neuron number if 300 for each category -- 2773 among 12 categories')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(300, ordered_neurons_gum) #GUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ba56c",
   "metadata": {},
   "source": [
    "#### 500 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4965a016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 500 for each category -- 6000 among 12 categories',\n",
       " 'Unique neuron number if 500 for each category -- 4152 among 12 categories')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(500, ordered_neurons_ewt) #EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf3f3d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 500 for each category -- 6000 among 12 categories',\n",
       " 'Unique neuron number if 500 for each category -- 4108 among 12 categories')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(500, ordered_neurons_gum) #GUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36ba78",
   "metadata": {},
   "source": [
    "#### 1000 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe711814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 1000 for each category -- 12000 among 12 categories',\n",
       " 'Unique neuron number if 1000 for each category -- 6476 among 12 categories')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(1000, ordered_neurons_ewt) #EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d456d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All neuron number if 1000 for each category -- 12000 among 12 categories',\n",
       " 'Unique neuron number if 1000 for each category -- 6417 among 12 categories')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_overall_common_neurons(1000, ordered_neurons_gum) #GUM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
