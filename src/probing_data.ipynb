{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c131092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from random import shuffle, seed\n",
    "from IPython.display import clear_output\n",
    "import neurox.data.extraction.transformers_extractor as transformers_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a83172",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = Path(os.getcwd()).parents[1]\n",
    "path_project = str(path_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06af485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/senya/Документы/project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14270cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b394200",
   "metadata": {},
   "source": [
    "Конвертируем файл, который получили из Probing_framework (уже получили, не в этом ноутбуке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fce99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertSample:\n",
    "    \n",
    "    \n",
    "    def __init__(self, path, train_size=2600, test_size=900, shuffle: bool = True): \n",
    "        self.shuffle = shuffle\n",
    "        self.path = path\n",
    "        self.category = re.search(r'[a-zA-Z]+(?=.csv)', path)[0]\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "\n",
    "    def read(self) -> list: \n",
    "        \"\"\"\n",
    "        Reads a file\n",
    "        Args:\n",
    "            path: a path to a file\n",
    "        \"\"\"\n",
    "        with open(self.path, encoding=\"utf-8\") as f:\n",
    "            lines = [line.split('\\t') for line in f]\n",
    "            if self.shuffle:\n",
    "                shuffle(lines)\n",
    "                \n",
    "        return lines\n",
    "    \n",
    "    def stupid_cycle(self, values, dct, number) -> dict: #util для семплинга\n",
    "        \n",
    "        dict_filter = {}\n",
    "        \n",
    "        for value in values:\n",
    "            i = 0\n",
    "            for k, v in dct.items():\n",
    "                if v == value:\n",
    "                    if i < number:\n",
    "                        dict_filter[k] = v\n",
    "                        i+=1\n",
    "                \n",
    "        return dict_filter\n",
    "                \n",
    "    def stupid_sampler(self) -> dict: #семплинг данных\n",
    "        \n",
    "        sents = self.read()\n",
    "        values = []\n",
    "        values_train = []\n",
    "        values_test = []\n",
    "        sents_train = []\n",
    "        sents_test = []\n",
    "\n",
    "        for line in sents:\n",
    "            part, value, sentence = line[0], line[1], line[2]\n",
    "            if value not in values:\n",
    "                values.append(value)\n",
    "            if 5 < len(sentence.split()) < 40:\n",
    "                if part == 'tr':\n",
    "                    values_train.append(value)\n",
    "                    sents_train.append(sentence)\n",
    "                if part =='te' or part=='va':\n",
    "                    values_test.append(value)\n",
    "                    sents_test.append(sentence)\n",
    "\n",
    "        train_dict = dict(zip(sents_train, values_train))  \n",
    "        test_dict = dict(zip(sents_test, values_test))\n",
    "\n",
    "        values = set(values)\n",
    "        number_one = round(self.train_size/len(values))\n",
    "        number_two = round(self.test_size/len(values))\n",
    "\n",
    "        dict_filter_train = self.stupid_cycle(values, train_dict, number_one)\n",
    "        dict_filter_test = self.stupid_cycle(values, test_dict, number_two)\n",
    "        return dict_filter_train, dict_filter_test\n",
    "    \n",
    "    def permute(self, dct) -> dict:\n",
    "        l = list(dct.items())\n",
    "        shuffle(l)\n",
    "        return dict(l)\n",
    "        \n",
    "    def writer(self) -> str: #пишем в файлы\n",
    "        \n",
    "        \"\"\"\n",
    "        Writes to a file\n",
    "        \"\"\"\n",
    "        \n",
    "        if re.search(r'(?<=\\/)[a-zA-Z][a-zA-Z]_[a-zA-Z]+(?=_)', self.path)[0]:\n",
    "            dataset = re.search(r'(?<=\\/)[a-zA-Z][a-zA-Z]_[a-zA-Z]+(?=_)', self.path)[0]\n",
    "            path = path_project+f'/large_data_{dataset}'\n",
    "        else:\n",
    "            path = path_project+'/large_data'\n",
    "            \n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        if not os.path.isdir(path+f'/data_{self.category}'):\n",
    "            os.mkdir(path+f'/data_{self.category}')\n",
    "        \n",
    "        result_path_datatrain = path+f\"/data_{self.category}/datatrain_{self.category}.txt\"\n",
    "        result_path_labeltrain = path+f\"/data_{self.category}/labeltrain_{self.category}.txt\"\n",
    "        \n",
    "        \n",
    "        result_path_datatest = path+f\"/data_{self.category}/datatest_{self.category}.txt\"\n",
    "        result_path_labeltest = path+f\"/data_{self.category}/labeltest_{self.category}.txt\"\n",
    "        \n",
    "        with open(result_path_datatrain, \"w\", encoding=\"utf-8\") as traindata, \\\n",
    "             open(result_path_labeltrain, \"w\", encoding=\"utf-8\") as trainlabel, \\\n",
    "             open(result_path_datatest, \"w\", encoding=\"utf-8\") as testdata, \\\n",
    "             open(result_path_labeltest, \"w\", encoding=\"utf-8\") as testlabel:\n",
    "            \n",
    "            \n",
    "            dict_filter_train, dict_filter_test = self.stupid_sampler()\n",
    "            if self.shuffle:\n",
    "                dict_filter_train = self.permute(dict_filter_train)\n",
    "                dict_filter_test = self.permute(dict_filter_test)\n",
    "    \n",
    "            \n",
    "            for sentence, value in dict_filter_train.items():\n",
    "                traindata.writelines(sentence)\n",
    "                trainlabel.writelines(value + '\\n')\n",
    "\n",
    "\n",
    "            for sentence, value in dict_filter_test.items():\n",
    "                testdata.writelines(sentence)\n",
    "                testlabel.writelines(value + '\\n')\n",
    "                                                                  \n",
    "        \n",
    "        return result_path_datatrain, result_path_labeltrain, result_path_datatest, result_path_labeltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd55ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self, path_trdata, path_tedata):\n",
    "        \n",
    "        self.path_trdata = path_trdata\n",
    "        self.path_trlabel = path_trlabel\n",
    "        self.path_tedata = path_tedata\n",
    "        self.path_telabel = path_telabel\n",
    "        self.category = re.search(r'(?<=_)[a-zA-Z]+(?=.txt)', path_trdata)[0]\n",
    "        self.dataset = re.search(r'(?<=_)[a-zA-Z]+_[a-zA-Z]+(?=\\/)', path_trdata)[0]\n",
    "        \n",
    "    def jsons(self, model):\n",
    "        \n",
    "        path = path_project+f'/large_data_{self.dataset}/data_{self.category}'\n",
    "        \n",
    "        \n",
    "        transformers_extractor.extract_representations(model,\n",
    "        self.path_trdata,\n",
    "        path+'/activations_train.json',\n",
    "        aggregation=\"average\" #last, first\n",
    "        )\n",
    "        \n",
    "        transformers_extractor.extract_representations(model,\n",
    "        self.path_tedata,\n",
    "        path+'/activations_te.json',\n",
    "        aggregation=\"average\" #last, first\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65eb0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for dirname, _, filenames in os.walk(path_project+'/data'):\n",
    "    for filename in filenames: #обходим все файлы-категории\n",
    "        file = os.path.join(dirname, filename)\n",
    "        if not re.search(r'/data/.gitignore', file):\n",
    "            files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fc4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    splitter = ConvertSample(file)\n",
    "    \n",
    "    #получаем трейновую и тестовую выборку\n",
    "    path_trdata, path_trlabel, path_tedata, path_telabel = splitter.writer()\n",
    "    \n",
    "    #получаем эмбеддинги\n",
    "    data = Data(path_trdata, path_tedata)\n",
    "    data.jsons('bert-base-uncased')\n",
    "    clear_output(wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
